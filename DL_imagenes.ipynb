{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-imagenes.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcms2665/GoogleEarthEngine/blob/master/DL_imagenes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leNfpN_ZpyTy"
      },
      "source": [
        "<center>\r\n",
        "  <img src=\"https://drive.google.com/uc?export=view&id=1578Q-90caRQKHlFMq8HEj2GIGPLkX8-b\" alt=\"centered image\" />\r\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-4Qv25Up9WL"
      },
      "source": [
        "<H1 align=\"center\"> <b>Estimación de áreas pequeñas </b></H1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EROWD2dAqA9P"
      },
      "source": [
        "Esta sección forma parte del análisis empírico del proyecto. La intención es consolidar un único documento en donde se concentre a la información geográfica y estadística.  Este es el primer ejercicio con **redes neuronales** para clasificar las imagenes de Google Earth con las siguientes características:\r\n",
        "\r\n",
        "\r\n",
        "| Características del modelo   |            |\r\n",
        "|----------|:-------------:|\r\n",
        "| Modelo |  Secuencial |\r\n",
        "| Épocas |    10   |\r\n",
        "| Optimizador | Adam |\r\n",
        "| Función de costo |    categorical_crossentropy   |\r\n",
        "| Métrica | accuracy |\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Se utilizaron los tutoriales de GEE y *tensorflow*.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYyTIPLsvMWl",
        "cellView": "code"
      },
      "source": [
        "# Librerías\n",
        "import ee\n",
        "import tensorflow as tf\n",
        "import folium\n",
        "import time\n",
        "\n",
        "# Token\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrXLkJC2QJdP"
      },
      "source": [
        "# Definición de objetos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHTOc5YLQZ5B"
      },
      "source": [
        "# Acá se guardan todos los objetos que se utilizan en el proceso\n",
        "\n",
        "# 0. Usuario de GCloud\n",
        "\n",
        "OUTPUT_BUCKET = 'jcms2665_2'\n",
        "\n",
        "# 1. Imágenes \n",
        "\n",
        "L8SR = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
        "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
        "\n",
        "#1.1 Características \n",
        "      # Base etiquetada de prueba y validación\n",
        "LABEL_DATA = ee.FeatureCollection('projects/google/demo_landcover_labels')\n",
        "\n",
        "      # Propiedad (variable) en donde se guarda la etiqueta\n",
        "LABEL = 'landcover'; N_CLASSES = 3\n",
        "\n",
        "      # Lista de las Bandas y sus etiquetas\n",
        "FEATURE_NAMES = list(BANDS); FEATURE_NAMES.append(LABEL)\n",
        "\n",
        "#1.2 Archivos creados\n",
        "\n",
        "      # Archivos TFRecord que se exportarán a GEE y GCloud\n",
        "TRAIN_FILE_PREFIX = 'Training_demo'\n",
        "TEST_FILE_PREFIX = 'Testing_demo'\n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TEST_FILE_PREFIX + file_extension\n",
        "\n",
        "      # Archivo de predicción (imagen). \n",
        "      # El modelo entrenado leerá archivo y clasificará los píxeles.\n",
        "IMAGE_FILE_PREFIX = 'Image_pixel_demo_'\n",
        "\n",
        "      # Archivo con las imágenes clasificadas\n",
        "OUTPUT_IMAGE_FILE = 'gs://' + OUTPUT_BUCKET + '/Classified_pixel_demo.TFRecord'\n",
        "\n",
        "      # Exportar imágenes en esta región: Corredor\n",
        "EXPORT_REGION = ee.Geometry.Rectangle([-98.01, 20.4, -102.35, 21.27])\n",
        "\n",
        "      # Archivo que se creará al exportar los datos a este archivo\n",
        "OUTPUT_ASSET_ID = 'users/' + 'jcms2665' + '/Classified_pixel_demo'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcjQnHH8zT4q"
      },
      "source": [
        "# Datos de GEE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJYucYe3SPPr"
      },
      "source": [
        "# Función máscara nubes\n",
        "def maskL8sr(image):\n",
        "  cloudShadowBitMask = ee.Number(2).pow(3).int()\n",
        "  cloudsBitMask = ee.Number(2).pow(5).int()\n",
        "  qa = image.select('pixel_qa')\n",
        "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0).And(\n",
        "    qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  return image.updateMask(mask).select(BANDS).divide(10000)\n",
        "\n",
        "# Rango de fechas y mediana de las imágenes\n",
        "image = L8SR.filterDate('2018-01-01', '2018-12-31').map(maskL8sr).median()\n",
        "\n",
        "# Mostrar mapa y vincular con GEE\n",
        "mapid = image.getMapId({'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3})\n",
        "map = folium.Map(location=[21.16, -100.79])\n",
        "\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='median composite',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOedOKyRExHE"
      },
      "source": [
        "# Muestras aleatorias\n",
        "sample = image.sampleRegions(\n",
        "  collection=LABEL_DATA, properties=[LABEL], scale=10).randomColumn()\n",
        "\n",
        "# Partición de la muestra 70-30.\n",
        "training = sample.filter(ee.Filter.lt('random', 0.7))\n",
        "testing = sample.filter(ee.Filter.gte('random', 0.3))\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Verificación: se imprime la primera pareja de puntos.\n",
        "pprint({'training': training.first().getInfo()})\n",
        "pprint({'testing': testing.first().getInfo()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb-aPvQc0Xvp"
      },
      "source": [
        "# Acceso a mi cuenta de google Cloud\n",
        "print('Acceso.' if tf.io.gfile.exists('gs://' + OUTPUT_BUCKET) \n",
        "    else 'Sin acceso')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVNQzg8R6Wy"
      },
      "source": [
        "# Crear las tareas (funciones)\n",
        "training_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=training,\n",
        "  description='Training Export',\n",
        "  fileNamePrefix=TRAIN_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "testing_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=testing,\n",
        "  description='Testing Export',\n",
        "  fileNamePrefix=TEST_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "# Exportación\n",
        "training_task.start()\n",
        "testing_task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEWvS5ekcEq0"
      },
      "source": [
        "# Imprimir\n",
        "pprint(ee.batch.Task.list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDZfNl6yc0Kj"
      },
      "source": [
        "print('Listo datos de entrenamiento.' if tf.io.gfile.exists(TRAIN_FILE_PATH) \n",
        "    else 'No')\n",
        "print('Listo datos de prueba.' if tf.io.gfile.exists(TEST_FILE_PATH) \n",
        "    else 'No')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA8QA8oQVo8V"
      },
      "source": [
        "## Imágenes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVNhJYacVpEw"
      },
      "source": [
        "# Dimensiones y el archivo\n",
        "\n",
        "image_export_options = {\n",
        "  'patchDimensions': [256, 256],\n",
        "  'maxFileSize': 104857600,\n",
        "  'compressed': True\n",
        "}\n",
        "\n",
        "# Setup the task.\n",
        "image_task = ee.batch.Export.image.toCloudStorage(\n",
        "  image=image,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=IMAGE_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  scale=30,\n",
        "  fileFormat='TFRecord',\n",
        "  region=EXPORT_REGION.toGeoJSON()['coordinates'],\n",
        "  formatOptions=image_export_options,\n",
        ")\n",
        "\n",
        "# Ejecución de la tarea\n",
        "image_task.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmPHb779KOXm"
      },
      "source": [
        "# Imprimir\n",
        "pprint(ee.batch.Task.list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKZeZswloP11"
      },
      "source": [
        "while image_task.active():\n",
        "  print('sondeo para la tarea (id: {}).'.format(image_task.id))\n",
        "  time.sleep(30)\n",
        "print('Exportación de las imágenes listas')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWdH_wlZCEk"
      },
      "source": [
        "## Preparación y preprocesamiento de datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3PKyDQW8Vpx",
        "cellView": "code"
      },
      "source": [
        "# Cree un conjunto de datos a partir del archivo TFRecord en Cloud Storagee.\n",
        "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
        "# Imprima el primer registro para verificar.\n",
        "print(iter(train_dataset).next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrDYm-ibKR6t"
      },
      "source": [
        "## Estructura de sus datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6JVQV5HKHMZ",
        "cellView": "code"
      },
      "source": [
        "# Lista de características de longitud fija, todas las cuales son float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
        "]\n",
        "\n",
        "# Diccionario con nombres como claves, características como valores.\n",
        "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
        "\n",
        "pprint(features_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNfaUPbcjuCO"
      },
      "source": [
        "## Analizar el conjunto de datos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Q0g3fBj2kD",
        "cellView": "code"
      },
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Función sobre el conjunto de datos.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "# Imprima el primer registro analizado para comprobarlo.\n",
        "pprint(iter(parsed_dataset).next())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLCsxWOuEBmE"
      },
      "source": [
        "## NDVI\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT6v2RM_EB1E",
        "cellView": "code"
      },
      "source": [
        "def normalized_difference(a, b):\n",
        "  nd = (a - b) / (a + b)\n",
        "  nd_inf = (a - b) / (a + b + 0.000001)\n",
        "  return tf.where(tf.math.is_finite(nd), nd, nd_inf)\n",
        "\n",
        "def add_NDVI(features, label):\n",
        "  features['NDVI'] = normalized_difference(features['B5'], features['B4'])\n",
        "  return features, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEx1RAXOZQkS"
      },
      "source": [
        "# Modelo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9pWa54oG-xl"
      },
      "source": [
        "## Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCZq3VNpG--G",
        "cellView": "code"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Gregar el NDVI.\n",
        "input_dataset = parsed_dataset.map(add_NDVI)\n",
        "\n",
        "# Keras requiere entradas como una tupla. Función de costo\n",
        "# denominada categorical_crossentropy, la etiqueta necesita ser cambiada a una\n",
        "# forma vectorial\n",
        "\n",
        "def to_tuple(inputs, label):\n",
        "  return (tf.transpose(list(inputs.values())),\n",
        "          tf.one_hot(indices=label, depth=N_CLASSES))\n",
        "\n",
        "# Asigne la función to_tuple, shuffle y batch.\n",
        "input_dataset = input_dataset.map(to_tuple).batch(8)\n",
        "\n",
        "# Definir las capas del modelo.\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(N_CLASSES, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Compilar el modelo con la función de costo, el optimizador y la métrica.\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 10 épocas\n",
        "model.fit(x=input_dataset, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa4ex_4eKiyb"
      },
      "source": [
        "## Precisión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE6d7FsrMa1p",
        "cellView": "code"
      },
      "source": [
        "test_dataset = (\n",
        "  tf.data.TFRecordDataset(TEST_FILE_PATH, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(add_NDVI)\n",
        "    .map(to_tuple)\n",
        "    .batch(1))\n",
        "\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhHrnv3VR0DU"
      },
      "source": [
        "# Entrenar al modelo para clasificar una imagen de Earth Engine\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUv9WMpcVp8E"
      },
      "source": [
        "# Lista de todos los archivos que están en google cloud\n",
        "files_list = !gsutil ls 'gs://'{OUTPUT_BUCKET}\n",
        "\n",
        "# Obtener solo los archivos generados por la importación de imágenes\n",
        "exported_files_list = [s for s in files_list if IMAGE_FILE_PREFIX in s]\n",
        "\n",
        "# Obtenga la lista de archivos de imagen y el archivo del mezclador JSON.\n",
        "image_files_list = []\n",
        "json_file = None\n",
        "for f in exported_files_list:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    image_files_list.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    json_file = f\n",
        "\n",
        "# Los archivos deben estar en el orden correcto\n",
        "image_files_list.sort()\n",
        "\n",
        "pprint(image_files_list)\n",
        "print(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn7Dr0AAd93_"
      },
      "source": [
        "import json\n",
        "\n",
        "# Cargue el contenido del archivo del mezclador en un objeto JSON.\n",
        "json_text = !gsutil cat {json_file}\n",
        "# Obtenga una sola cadena con / newlines de IPython.utils.text.SList\n",
        "mixer = json.loads(json_text.nlstr)\n",
        "pprint(mixer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn8Kj3VfwpiJ",
        "cellView": "code"
      },
      "source": [
        "# Get relevant info from the JSON mixer file.\n",
        "patch_width = mixer['patchDimensions'][0]\n",
        "patch_height = mixer['patchDimensions'][1]\n",
        "patches = mixer['totalPatches']\n",
        "patch_dimensions_flat = [patch_width * patch_height, 1]\n",
        "\n",
        "# Los tensores tienen la forma de un parche, un parche para cada banda.\n",
        "image_columns = [\n",
        "  tf.io.FixedLenFeature(shape=patch_dimensions_flat, dtype=tf.float32) \n",
        "    for k in BANDS\n",
        "]\n",
        "\n",
        "# Diccionario de análisis.\n",
        "image_features_dict = dict(zip(BANDS, image_columns))\n",
        "\n",
        "# Tenga en cuenta que puede crear un conjunto de datos a partir de muchos archivos especificando una lista.\n",
        "image_dataset = tf.data.TFRecordDataset(image_files_list, compression_type='GZIP')\n",
        "\n",
        "# Función de análisis.\n",
        "def parse_image(example_proto):\n",
        "  return tf.io.parse_single_example(example_proto, image_features_dict)\n",
        "\n",
        "# Analice los datos en tensores, un tensor largo por parche.\n",
        "image_dataset = image_dataset.map(parse_image, num_parallel_calls=5)\n",
        "\n",
        "# Divide nuestros tensores largos en muchos pequeños.\n",
        "image_dataset = image_dataset.flat_map(\n",
        "  lambda features: tf.data.Dataset.from_tensor_slices(features)\n",
        ")\n",
        "\n",
        "# Agregue funciones adicionales (NDVI).\n",
        "image_dataset = image_dataset.map(\n",
        "  # Agregue NDVI a una función que no tiene etiqueta.\n",
        "  lambda features: add_NDVI(features, None)[0]\n",
        ")\n",
        "\n",
        "# Convierta el diccionario de cada registro en una tupla sin etiqueta.\n",
        "image_dataset = image_dataset.map(\n",
        "  lambda data_dict: (tf.transpose(list(data_dict.values())), )\n",
        ")\n",
        "\n",
        "# Convierta cada parche en un lote.\n",
        "image_dataset = image_dataset.batch(patch_width * patch_height)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2sfRemRRDkV"
      },
      "source": [
        "## Predicciones para los píxeles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VGhmiP_REBP"
      },
      "source": [
        "# Predicción por lotes, con tantos pasos como parches.\n",
        "predictions = model.predict(image_dataset, steps=patches, verbose=1)\n",
        "\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPU2VlPOikAy"
      },
      "source": [
        "## Predicciones "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkorbsEHepzJ"
      },
      "source": [
        "print('Writing to file ' + OUTPUT_IMAGE_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kATMknHc0qeR",
        "cellView": "code"
      },
      "source": [
        "# Inicializar writer.\n",
        "writer = tf.io.TFRecordWriter(OUTPUT_IMAGE_FILE)\n",
        "\n",
        "# Cada parche de predicciones, volcaremos un ejemplo en la salida.\n",
        "# archivo con una sola característica que contiene nuestras predicciones. Dado que nuestras predicciones\n",
        "# ya están en el orden de los datos exportados, los parches que creamos aquí\n",
        "# también estará en el orden correcto.\n",
        "patch = [[], [], [], []]\n",
        "cur_patch = 1\n",
        "for prediction in predictions:\n",
        "  patch[0].append(tf.argmax(prediction, 1))\n",
        "  patch[1].append(prediction[0][0])\n",
        "  patch[2].append(prediction[0][1])\n",
        "  patch[3].append(prediction[0][2])\n",
        "  # Una vez que hemos visto un valor de parches de class_ids ...\n",
        "  if (len(patch[0]) == patch_width * patch_height):\n",
        "    print('Done with patch ' + str(cur_patch) + ' of ' + str(patches) + '...')\n",
        "    # Crear ejemplos\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'prediction': tf.train.Feature(\n",
        "              int64_list=tf.train.Int64List(\n",
        "                  value=patch[0])),\n",
        "          'bareProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[1])),\n",
        "          'vegProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[2])),\n",
        "          'waterProb': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch[3])),\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "\n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = [[], [], [], []]\n",
        "    cur_patch += 1\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K_1hKs0aBdA"
      },
      "source": [
        "# Clasificación con datos de Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZVWDPefUCgA"
      },
      "source": [
        "!gsutil ls -l {OUTPUT_IMAGE_FILE}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXulMNl9lTDv",
        "cellView": "code"
      },
      "source": [
        "print('Uploading to ' + OUTPUT_ASSET_ID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V64tcVxsO5h6"
      },
      "source": [
        "# Empezar la subida\n",
        "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vB-gwGhl_3C",
        "cellView": "code"
      },
      "source": [
        "ee.batch.Task.list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEkVxIyJiFd4"
      },
      "source": [
        "predictions_image = ee.Image(OUTPUT_ASSET_ID)\n",
        "\n",
        "prediction_vis = {\n",
        "  'bands': 'prediction',\n",
        "  'min': 0,\n",
        "  'max': 2,\n",
        "  'palette': ['red', 'green', 'blue']\n",
        "}\n",
        "probability_vis = {'bands': ['bareProb', 'vegProb', 'waterProb'], 'max': 0.5}\n",
        "\n",
        "prediction_map_id = predictions_image.getMapId(prediction_vis)\n",
        "probability_map_id = predictions_image.getMapId(probability_vis)\n",
        "\n",
        "map = folium.Map(location=[21.16, -100.79])\n",
        "folium.TileLayer(\n",
        "  tiles=prediction_map_id['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='prediction',\n",
        ").add_to(map)\n",
        "folium.TileLayer(\n",
        "  tiles=probability_map_id['tile_fetcher'].url_format,\n",
        "  attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "  overlay=True,\n",
        "  name='probability',\n",
        ").add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}